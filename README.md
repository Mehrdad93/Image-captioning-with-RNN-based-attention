# Image-captioning-with-RNN-based-attention

We introduce an attention based model that automatically learns to generate a caption for images. Our model consists of a novel attention module which includes an elegant modification of GRU architecture. We validate the use of our attention model on a benchmark dataset MS COCO (2017), and compare its performance with other sate-of-the-art models. Our proposed model has the BLEU-1 score of 74.0.

More details can be found in the following file:
> Image_Captioning_with_GRU_based_Attention.pdf

> Scores.png

